{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-31T08:00:04.218400Z",
     "iopub.status.busy": "2025-01-31T08:00:04.217983Z",
     "iopub.status.idle": "2025-01-31T08:00:04.240770Z",
     "shell.execute_reply": "2025-01-31T08:00:04.240130Z",
     "shell.execute_reply.started": "2025-01-31T08:00:04.218316Z"
    },
    "papermill": {
     "duration": 0.034985,
     "end_time": "2023-02-03T17:34:16.564237",
     "exception": false,
     "start_time": "2023-02-03T17:34:16.529252",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os\n",
    "# for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "#     for filename in filenames:\n",
    "#         print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2025-01-31T08:00:04.242329Z",
     "iopub.status.busy": "2025-01-31T08:00:04.242069Z",
     "iopub.status.idle": "2025-01-31T08:00:09.798351Z",
     "shell.execute_reply": "2025-01-31T08:00:09.797345Z",
     "shell.execute_reply.started": "2025-01-31T08:00:04.242306Z"
    },
    "id": "N8H5ufxkc2mk",
    "papermill": {
     "duration": 5.123187,
     "end_time": "2023-02-03T17:34:21.732354",
     "exception": false,
     "start_time": "2023-02-03T17:34:16.609167",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "import requests\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "cellView": "form",
    "execution": {
     "iopub.execute_input": "2025-01-31T08:00:09.800285Z",
     "iopub.status.busy": "2025-01-31T08:00:09.799658Z",
     "iopub.status.idle": "2025-01-31T08:00:09.810640Z",
     "shell.execute_reply": "2025-01-31T08:00:09.809755Z",
     "shell.execute_reply.started": "2025-01-31T08:00:09.800257Z"
    },
    "id": "oKvj6lY6kZx8",
    "papermill": {
     "duration": 0.021359,
     "end_time": "2023-02-03T17:34:21.759489",
     "exception": false,
     "start_time": "2023-02-03T17:34:21.73813",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "original_image_cache = {}\n",
    "\n",
    "def preprocess_image(image):\n",
    "  image = np.array(image)\n",
    "  # reshape into shape [batch_size, height, width, num_channels]\n",
    "  img_reshaped = tf.reshape(image, [1, image.shape[0], image.shape[1], image.shape[2]])\n",
    "  # Use `convert_image_dtype` to convert to floats in the [0,1] range.\n",
    "  image = tf.image.convert_image_dtype(img_reshaped, tf.float32)\n",
    "  return image\n",
    "\n",
    "def load_image_from_url(img_url):\n",
    "  \"\"\"Returns an image with shape [1, height, width, num_channels].\"\"\"\n",
    "  user_agent = {'User-agent': 'Colab Sample (https://tensorflow.org)'}\n",
    "  response = requests.get(img_url, headers=user_agent)\n",
    "  image = Image.open(BytesIO(response.content))\n",
    "  image = preprocess_image(image)\n",
    "  return image\n",
    "\n",
    "def load_image(image_url, image_size=256, dynamic_size=False, max_dynamic_size=512):\n",
    "  \"\"\"Loads and preprocesses images.\"\"\"\n",
    "  # Cache image file locally.\n",
    "  if image_url in original_image_cache:\n",
    "    img = original_image_cache[image_url]\n",
    "  elif image_url.startswith('https://'):\n",
    "    img = load_image_from_url(image_url)\n",
    "  else:\n",
    "    fd = tf.io.gfile.GFile(image_url, 'rb')\n",
    "    img = preprocess_image(Image.open(fd))\n",
    "  original_image_cache[image_url] = img\n",
    "  # Load and convert to float32 numpy array, add batch dimension, and normalize to range [0, 1].\n",
    "  img_raw = img\n",
    "  if tf.reduce_max(img) > 1.0:\n",
    "    img = img / 255.\n",
    "  if len(img.shape) == 3:\n",
    "    img = tf.stack([img, img, img], axis=-1)\n",
    "  if not dynamic_size:\n",
    "    img = tf.image.resize_with_pad(img, image_size, image_size)\n",
    "  elif img.shape[1] > max_dynamic_size or img.shape[2] > max_dynamic_size:\n",
    "    img = tf.image.resize_with_pad(img, max_dynamic_size, max_dynamic_size)\n",
    "  return img, img_raw\n",
    "\n",
    "def show_image(image, title=''):\n",
    "  image_size = image.shape[1]\n",
    "  w = (image_size * 6) // 320\n",
    "  plt.figure(figsize=(w, w))\n",
    "  plt.imshow(image[0], aspect='equal')\n",
    "  plt.axis('off')\n",
    "  plt.title(title)\n",
    "  plt.show()\n",
    "\n",
    "image_size = 224\n",
    "dynamic_size = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-31T08:00:09.812098Z",
     "iopub.status.busy": "2025-01-31T08:00:09.811808Z",
     "iopub.status.idle": "2025-01-31T08:00:09.835563Z",
     "shell.execute_reply": "2025-01-31T08:00:09.834673Z",
     "shell.execute_reply.started": "2025-01-31T08:00:09.812075Z"
    },
    "id": "iQ3aamrBfs-c",
    "papermill": {
     "duration": 0.0146,
     "end_time": "2023-02-03T17:34:21.789682",
     "exception": false,
     "start_time": "2023-02-03T17:34:21.775082",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Select an Image Classification model\n",
    "\n",
    "model_name = \"vit-b8\"\n",
    "\n",
    "model_handle_map = {\n",
    "  \"vit-b8\": \"/kaggle/input/vision-transformer/tensorflow2/vit-b8-classification/1\",\n",
    "}\n",
    "\n",
    "\n",
    "model_image_size_map = {\n",
    "  \"vit-b8\": 224,\n",
    "}\n",
    "\n",
    "model_handle = model_handle_map[model_name]\n",
    "\n",
    "print(f\"Selected model: {model_name} : {model_handle}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2025-01-31T08:00:09.838832Z",
     "iopub.status.busy": "2025-01-31T08:00:09.838505Z",
     "iopub.status.idle": "2025-01-31T08:00:09.936013Z",
     "shell.execute_reply": "2025-01-31T08:00:09.935268Z",
     "shell.execute_reply.started": "2025-01-31T08:00:09.838790Z"
    },
    "papermill": {
     "duration": 0.133836,
     "end_time": "2023-02-03T17:34:21.928637",
     "exception": false,
     "start_time": "2023-02-03T17:34:21.794801",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "max_dynamic_size = 512\n",
    "if model_name in model_image_size_map:\n",
    "  image_size = model_image_size_map[model_name]\n",
    "  dynamic_size = False\n",
    "  print(f\"Images will be converted to {image_size}x{image_size}\")\n",
    "else:\n",
    "  dynamic_size = True\n",
    "  print(f\"Images will be capped to a max size of {max_dynamic_size}x{max_dynamic_size}\")\n",
    "\n",
    "labels_file = \"https://storage.googleapis.com/download.tensorflow.org/data/ImageNetLabels.txt\"\n",
    "\n",
    "#download labels and creates a maps\n",
    "downloaded_file = tf.keras.utils.get_file(\"labels.txt\", origin=labels_file)\n",
    "\n",
    "classes = []\n",
    "\n",
    "with open(downloaded_file) as f:\n",
    "  labels = f.readlines()\n",
    "  classes = [l.strip() for l in labels]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.005205,
     "end_time": "2023-02-03T17:34:21.940223",
     "exception": false,
     "start_time": "2023-02-03T17:34:21.935018",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Select an Input Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e7vkdUqpBkfE",
    "papermill": {
     "duration": 0.006461,
     "end_time": "2023-02-03T17:34:37.409513",
     "exception": false,
     "start_time": "2023-02-03T17:34:37.403052",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Everything is ready for inference. Here you can see the top 5 results from the model for the selected image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.008788,
     "end_time": "2023-02-03T17:34:37.608075",
     "exception": false,
     "start_time": "2023-02-03T17:34:37.599287",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Using Kaggle Models for Transfer Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.007291,
     "end_time": "2023-02-03T17:34:37.622886",
     "exception": false,
     "start_time": "2023-02-03T17:34:37.615595",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Select a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-31T08:00:09.977066Z",
     "iopub.status.busy": "2025-01-31T08:00:09.976791Z",
     "iopub.status.idle": "2025-01-31T08:00:09.986974Z",
     "shell.execute_reply": "2025-01-31T08:00:09.986096Z",
     "shell.execute_reply.started": "2025-01-31T08:00:09.977045Z"
    },
    "papermill": {
     "duration": 0.017714,
     "end_time": "2023-02-03T17:34:37.648195",
     "exception": false,
     "start_time": "2023-02-03T17:34:37.630481",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model_name = \"vit-b8\"\n",
    "\n",
    "model_handle_map = {\n",
    "  \"vit-b8\": \"/kaggle/input/vision-transformer/tensorflow2/vit-b8-fe/1\",\n",
    "}\n",
    "\n",
    "model_image_size_map = {\n",
    "  \"vit-b8\": 224,\n",
    "}\n",
    "\n",
    "model_handle = model_handle_map.get(model_name)\n",
    "pixels = model_image_size_map.get(model_name, 224)\n",
    "\n",
    "print(f\"Selected model: {model_name} : {model_handle}\")\n",
    "\n",
    "IMAGE_SIZE = (pixels, pixels)\n",
    "print(f\"Input size {IMAGE_SIZE}\")\n",
    "\n",
    "BATCH_SIZE = 16#@param {type:\"integer\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-31T08:00:09.988978Z",
     "iopub.status.busy": "2025-01-31T08:00:09.988267Z",
     "iopub.status.idle": "2025-01-31T08:00:10.000859Z",
     "shell.execute_reply": "2025-01-31T08:00:10.000030Z",
     "shell.execute_reply.started": "2025-01-31T08:00:09.988943Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "data_dir = '/kaggle/input/blind-app-ds-300/blind_app_dataset_300'\n",
    "print(data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.007561,
     "end_time": "2023-02-03T17:34:37.665457",
     "exception": false,
     "start_time": "2023-02-03T17:34:37.657896",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Select a dataset to fine-tune the model against"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2025-01-31T08:00:10.002457Z",
     "iopub.status.busy": "2025-01-31T08:00:10.002178Z",
     "iopub.status.idle": "2025-01-31T08:00:14.101042Z",
     "shell.execute_reply": "2025-01-31T08:00:14.100162Z",
     "shell.execute_reply.started": "2025-01-31T08:00:10.002409Z"
    },
    "papermill": {
     "duration": 8.82833,
     "end_time": "2023-02-03T17:34:46.501641",
     "exception": false,
     "start_time": "2023-02-03T17:34:37.673311",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 300 files belonging to 14 classes.\n",
      "Using 270 files for training.\n",
      "Found 300 files belonging to 14 classes.\n",
      "Using 30 files for validation.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def build_dataset(subset):\n",
    "  return tf.keras.preprocessing.image_dataset_from_directory(\n",
    "      data_dir,\n",
    "      validation_split=.10,\n",
    "      subset=subset,\n",
    "      label_mode=\"categorical\",\n",
    "      seed=123,\n",
    "      image_size=IMAGE_SIZE,\n",
    "      batch_size=1)\n",
    "\n",
    "train_ds = build_dataset(\"training\")\n",
    "class_names = tuple(train_ds.class_names)\n",
    "train_size = train_ds.cardinality().numpy()\n",
    "train_ds = train_ds.unbatch().batch(BATCH_SIZE)\n",
    "train_ds = train_ds.repeat()\n",
    "\n",
    "normalization_layer = tf.keras.layers.Rescaling(1. / 255)\n",
    "preprocessing_model = tf.keras.Sequential([normalization_layer])\n",
    "do_data_augmentation = False #@param {type:\"boolean\"}\n",
    "if do_data_augmentation:\n",
    "  preprocessing_model.add(\n",
    "      tf.keras.layers.RandomRotation(40))\n",
    "  preprocessing_model.add(\n",
    "      tf.keras.layers.RandomTranslation(0, 0.2))\n",
    "  preprocessing_model.add(\n",
    "      tf.keras.layers.RandomTranslation(0.2, 0))\n",
    "  # Like the old tf.keras.preprocessing.image.ImageDataGenerator(),\n",
    "  # image sizes are fixed when reading, and then a random zoom is applied.\n",
    "  # If all training inputs are larger than image_size, one could also use\n",
    "  # RandomCrop with a batch size of 1 and rebatch later.\n",
    "  preprocessing_model.add(\n",
    "      tf.keras.layers.RandomZoom(0.2, 0.2))\n",
    "  preprocessing_model.add(\n",
    "      tf.keras.layers.RandomFlip(mode=\"horizontal\"))\n",
    "train_ds = train_ds.map(lambda images, labels:\n",
    "                        (preprocessing_model(images), labels))\n",
    "\n",
    "val_ds = build_dataset(\"validation\")\n",
    "valid_size = val_ds.cardinality().numpy()\n",
    "val_ds = val_ds.unbatch().batch(BATCH_SIZE)\n",
    "val_ds = val_ds.map(lambda images, labels:\n",
    "                    (normalization_layer(images), labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.01354,
     "end_time": "2023-02-03T17:34:46.530896",
     "exception": false,
     "start_time": "2023-02-03T17:34:46.517356",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Defining the model.\n",
    "\n",
    "All it takes is to put a linear classifier on top of the `feature_extractor_layer` with the Hub module.\n",
    "\n",
    "For speed, we start out with a non-trainable `feature_extractor_layer`, but you can also enable fine-tuning for greater accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-31T08:00:14.111422Z",
     "iopub.status.busy": "2025-01-31T08:00:14.111139Z",
     "iopub.status.idle": "2025-01-31T08:00:24.105475Z",
     "shell.execute_reply": "2025-01-31T08:00:24.104287Z",
     "shell.execute_reply.started": "2025-01-31T08:00:14.111398Z"
    },
    "papermill": {
     "duration": 6.44893,
     "end_time": "2023-02-03T17:34:52.993834",
     "exception": false,
     "start_time": "2023-02-03T17:34:46.544904",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building model with /kaggle/input/vision-transformer/tensorflow2/vit-b8-fe/1\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "keras_layer (KerasLayer)     (None, 768)               85807872  \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 768)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 14)                10766     \n",
      "=================================================================\n",
      "Total params: 85,818,638\n",
      "Trainable params: 10,766\n",
      "Non-trainable params: 85,807,872\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "do_fine_tuning = False \n",
    "\n",
    "print(\"Building model with\", model_handle)\n",
    "model = tf.keras.Sequential([\n",
    "    # Explicitly define the input shape so the model can be properly\n",
    "    # loaded by the TFLiteConverter\n",
    "    tf.keras.layers.InputLayer(input_shape=IMAGE_SIZE + (3,)),\n",
    "    hub.KerasLayer(model_handle, trainable=do_fine_tuning),\n",
    "    tf.keras.layers.Dropout(rate=0.2),\n",
    "    tf.keras.layers.Dense(len(class_names),\n",
    "                          kernel_regularizer=tf.keras.regularizers.l2(0.0001))\n",
    "])\n",
    "model.build((None,)+IMAGE_SIZE+(3,))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.014175,
     "end_time": "2023-02-03T17:34:53.023003",
     "exception": false,
     "start_time": "2023-02-03T17:34:53.008828",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-31T08:00:24.115761Z",
     "iopub.status.busy": "2025-01-31T08:00:24.115201Z",
     "iopub.status.idle": "2025-01-31T08:01:52.327772Z",
     "shell.execute_reply": "2025-01-31T08:01:52.326840Z",
     "shell.execute_reply.started": "2025-01-31T08:00:24.115727Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "  optimizer=tf.keras.optimizers.SGD(learning_rate=0.004, momentum=0.9), \n",
    "  loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True, label_smoothing=0.1),\n",
    "  metrics=['accuracy'])\n",
    "\n",
    "steps_per_epoch = train_size // BATCH_SIZE\n",
    "validation_steps = valid_size // BATCH_SIZE\n",
    "\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "# Callbacks\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, min_lr=0.0001, verbose=1)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, verbose=1, restore_best_weights=True)\n",
    "\n",
    "# Fit the model\n",
    "hist = model.fit(\n",
    "    train_ds,\n",
    "    epochs=15,  # Increase epochs since early stopping will terminate early if needed\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    validation_data=val_ds,\n",
    "    validation_steps=validation_steps,\n",
    "    callbacks=[reduce_lr, early_stopping]\n",
    ").history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-31T08:01:52.329462Z",
     "iopub.status.busy": "2025-01-31T08:01:52.329082Z",
     "iopub.status.idle": "2025-01-31T08:01:58.419753Z",
     "shell.execute_reply": "2025-01-31T08:01:58.418788Z",
     "shell.execute_reply.started": "2025-01-31T08:01:52.329425Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Evaluate the model on the validation dataset\n",
    "val_loss, val_accuracy = model.evaluate(val_ds, verbose=1)\n",
    "\n",
    "print(f\"Validation Loss: {val_loss}\")\n",
    "print(f\"Validation Accuracy: {val_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-31T08:01:58.428704Z",
     "iopub.status.busy": "2025-01-31T08:01:58.427973Z",
     "iopub.status.idle": "2025-01-31T08:02:05.175509Z",
     "shell.execute_reply": "2025-01-31T08:02:05.174551Z",
     "shell.execute_reply.started": "2025-01-31T08:01:58.428669Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Initialize lists for true and predicted labels\n",
    "y_true_indices = []\n",
    "y_pred_indices = []\n",
    "y_score_list = []\n",
    "\n",
    "# Loop through the validation dataset\n",
    "for x_batch, y_batch in val_ds:\n",
    "    # Loop through each image in the batch\n",
    "    for i in range(len(x_batch)):\n",
    "        # Extract the image and its true label\n",
    "        image = x_batch[i]\n",
    "        true_index = np.argmax(y_batch[i])  # True label index\n",
    "        y_true_indices.append(true_index)\n",
    "        \n",
    "        # Predict the label\n",
    "        prediction_scores = model.predict(np.expand_dims(image, axis=0), verbose=0)\n",
    "        \n",
    "        y_scores_prob = np.exp(prediction_scores) / np.sum(np.exp(prediction_scores), axis=1, keepdims=True)\n",
    "        y_score_list.append(y_scores_prob)\n",
    "        \n",
    "        predicted_index = np.argmax(prediction_scores)  # Predicted label index\n",
    "        y_pred_indices.append(predicted_index)\n",
    "\n",
    "# Print the collected indices\n",
    "print(\"y_true_indices:\", y_true_indices[:15])  # Show first 15 for brevity\n",
    "print(\"y_pred_indices:\", y_pred_indices[:15])  # Show first 15 for brevity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-31T08:02:05.177927Z",
     "iopub.status.busy": "2025-01-31T08:02:05.176701Z",
     "iopub.status.idle": "2025-01-31T08:02:06.148772Z",
     "shell.execute_reply": "2025-01-31T08:02:06.147805Z",
     "shell.execute_reply.started": "2025-01-31T08:02:05.177894Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Initialize a dictionary to count the occurrences of each class\n",
    "class_counts = {class_name: 0 for class_name in class_names}\n",
    "\n",
    "# Iterate through the validation dataset to count class occurrences\n",
    "for _, labels in val_ds.unbatch():\n",
    "    class_indices = np.argmax(labels.numpy(), axis=-1)  # Get class index for each label\n",
    "    class_name = class_names[class_indices]\n",
    "    class_counts[class_name] += 1\n",
    "\n",
    "# Extract class names and counts for plotting\n",
    "classes = list(class_counts.keys())\n",
    "counts = list(class_counts.values())\n",
    "\n",
    "# Plot the frequency distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(classes, counts, color=\"skyblue\", edgecolor=\"black\", alpha=0.7)\n",
    "plt.xticks(rotation=45, ha=\"right\", fontsize=10)  # Rotate class names for readability\n",
    "plt.title(\"Frequency of Each Class in Validation Dataset\", fontsize=14, fontweight=\"bold\")\n",
    "plt.xlabel(\"Class Name\", fontsize=12)\n",
    "plt.ylabel(\"Number of Images\", fontsize=12)\n",
    "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "# for i, count in enumerate(counts):\n",
    "#     plt.text(i, count + 0.5, str(count), ha='center', fontsize=10, fontweight=\"bold\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"class_frequency_plot.png\", dpi=300)  # Save the plot for journal submission\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-31T08:02:06.156959Z",
     "iopub.status.busy": "2025-01-31T08:02:06.156509Z",
     "iopub.status.idle": "2025-01-31T08:02:06.439495Z",
     "shell.execute_reply": "2025-01-31T08:02:06.438567Z",
     "shell.execute_reply.started": "2025-01-31T08:02:06.156924Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Assuming y_true and y_pred are arrays of shape (1677, 13) with class indices\n",
    "\n",
    "# Accuracy\n",
    "accuracy = accuracy_score(y_true_indices, y_pred_indices)\n",
    "print(f\"Accuracy: {accuracy:.6f}\")\n",
    "\n",
    "# Precision, Recall, and F1-Score for multi-class classification (use 'weighted' average to account for class imbalance)\n",
    "precision = precision_score(y_true_indices, y_pred_indices, average='weighted')\n",
    "recall = recall_score(y_true_indices, y_pred_indices, average='weighted')\n",
    "f1 = f1_score(y_true_indices, y_pred_indices, average='weighted')\n",
    "\n",
    "print(f\"Precision: {precision:.6f}\")\n",
    "print(f\"Recall: {recall:.6f}\")\n",
    "print(f\"F1-Score: {f1:.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2025-01-31T08:02:06.446884Z",
     "iopub.status.busy": "2025-01-31T08:02:06.446550Z",
     "iopub.status.idle": "2025-01-31T08:02:06.851502Z",
     "shell.execute_reply": "2025-01-31T08:02:06.850689Z",
     "shell.execute_reply.started": "2025-01-31T08:02:06.446849Z"
    },
    "papermill": {
     "duration": 1.066882,
     "end_time": "2023-02-03T17:35:43.724923",
     "exception": false,
     "start_time": "2023-02-03T17:35:42.658041",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "x, y = next(iter(val_ds))\n",
    "image = x[1, :, :, :]\n",
    "true_index = np.argmax(y[1])\n",
    "plt.imshow(image)\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "# Expand the validation image to (1, 224, 224, 3) before predicting the label\n",
    "prediction_scores = model.predict(np.expand_dims(image, axis=0))\n",
    "predicted_index = np.argmax(prediction_scores)\n",
    "print(\"True label: \" + class_names[true_index])\n",
    "print(\"Predicted label: \" + class_names[predicted_index])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-31T08:02:06.852933Z",
     "iopub.status.busy": "2025-01-31T08:02:06.852635Z",
     "iopub.status.idle": "2025-01-31T08:02:06.857565Z",
     "shell.execute_reply": "2025-01-31T08:02:06.856467Z",
     "shell.execute_reply.started": "2025-01-31T08:02:06.852908Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "print(type(val_ds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-31T08:02:06.859241Z",
     "iopub.status.busy": "2025-01-31T08:02:06.858687Z",
     "iopub.status.idle": "2025-01-31T08:02:09.571099Z",
     "shell.execute_reply": "2025-01-31T08:02:09.570152Z",
     "shell.execute_reply.started": "2025-01-31T08:02:06.859216Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "true_labels = []\n",
    "predicted_labels = []\n",
    "tot_times = []\n",
    "# Iterate over all batches in val_ds\n",
    "for x, y in val_ds:\n",
    "    batch_size = x.shape[0]  # Get batch size\n",
    "    \n",
    "    for i in range(batch_size):  # Iterate over each sample in the batch\n",
    "        st = time.time()\n",
    "        image = x[i, :, :, :]\n",
    "        true_index = np.argmax(y[i])  # Get predicted class index\n",
    "\n",
    "        # Debug: Print values to check if they are valid\n",
    "        print(f\"Sample {len(true_labels)}: true_index={true_index}, class_names length={len(class_names)}\")\n",
    "\n",
    "        # Check if index is valid before accessing class_names\n",
    "        if true_index >= len(class_names):\n",
    "            print(f\"Warning: true_index {true_index} is out of bounds!\")\n",
    "            continue  # Skip this entry to avoid crashing\n",
    "        \n",
    "        # Expand the validation image before predicting\n",
    "        \n",
    "        prediction_scores = model.predict(np.expand_dims(image, axis=0))\n",
    "        \n",
    "        predicted_index = np.argmax(prediction_scores)\n",
    "        \n",
    "        et = time.time()\n",
    "        # Store the labels\n",
    "        tot_times.append(et-st)\n",
    "        true_labels.append(class_names[true_index])\n",
    "        predicted_labels.append(class_names[predicted_index])\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-31T08:02:09.572903Z",
     "iopub.status.busy": "2025-01-31T08:02:09.572455Z",
     "iopub.status.idle": "2025-01-31T08:02:09.578455Z",
     "shell.execute_reply": "2025-01-31T08:02:09.577446Z",
     "shell.execute_reply.started": "2025-01-31T08:02:09.572805Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(len(true_labels))\n",
    "print(len(predicted_labels))\n",
    "\n",
    "print(true_labels)\n",
    "print(predicted_labels)\n",
    "\n",
    "print(\"ART:\", sum(tot_times)/len(tot_times))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-31T08:02:09.579751Z",
     "iopub.status.busy": "2025-01-31T08:02:09.579516Z",
     "iopub.status.idle": "2025-01-31T08:02:09.592792Z",
     "shell.execute_reply": "2025-01-31T08:02:09.591848Z",
     "shell.execute_reply.started": "2025-01-31T08:02:09.579730Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def time_to_minutes(time_str):\n",
    "    # Handle times like 12, 11:30, 10:30, etc.\n",
    "    if \"_\" in time_str:  # For times like 12:30, 10:30, etc.\n",
    "        hour, minute = map(int, time_str.split(\"_\"))\n",
    "    else:  # For times like 12, 11, 10, etc.\n",
    "        hour, minute = int(time_str), 0\n",
    "    # print(hour,minute)\n",
    "    # If hour is greater than or equal to 1, add 12 hours\n",
    "    if hour == 1 or hour == 2 or hour == 3:\n",
    "        hour += 12\n",
    "    \n",
    "    return hour * 60 + minute\n",
    "\n",
    "def calculate_time_difference(gt_val, out_val):\n",
    "    # Convert both gt_val and out_val to minutes\n",
    "    gt_time_in_minutes = time_to_minutes(gt_val)\n",
    "    out_time_in_minutes = time_to_minutes(out_val)\n",
    "\n",
    "    # print(gt_time_in_minutes, out_time_in_minutes, similar_cnt)\n",
    "    # Calculate the absolute difference\n",
    "    return abs(gt_time_in_minutes - out_time_in_minutes)\n",
    "\n",
    "# print(len(gt_value), len(out_pred))\n",
    "# out_pred = ['0' if val is None else val for val in out_pred]\n",
    "# print(out_pred)\n",
    "# Example for the 5 iterations\n",
    "size = 30\n",
    "tot_dig = 0\n",
    "similar_cnt = 0\n",
    "# print(true_labels)\n",
    "# print(predicted_labels)\n",
    "for i in range(size):\n",
    "    gt_val = str(true_labels[i]).replace(\" \", \"\")\n",
    "    out_val = str(predicted_labels[i]).replace(\" \", \"\")\n",
    "    time_diff = calculate_time_difference(gt_val, out_val)\n",
    "    if time_diff == 0:\n",
    "        similar_cnt += 1\n",
    "    tot_dig += time_diff * 0.5\n",
    "\n",
    "print(\"MAE:\", tot_dig / size, \"degree\")\n",
    "print(\"Accuracy:\", (similar_cnt / size) * 100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-31T08:02:09.623994Z",
     "iopub.status.busy": "2025-01-31T08:02:09.623615Z",
     "iopub.status.idle": "2025-01-31T08:02:10.527649Z",
     "shell.execute_reply": "2025-01-31T08:02:10.526303Z",
     "shell.execute_reply.started": "2025-01-31T08:02:09.623962Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# Example true labels and predicted labels\n",
    "# Replace these with your actual data\n",
    "y_true = np.array(y_true_indices)  # Replace with your true labels\n",
    "y_pred = np.array(y_pred_indices)  # Replace with your predicted labels\n",
    "\n",
    "# Define the class names (optional)\n",
    "class_names = [f\"Class {i}\" for i in range(len(np.unique(y_true)))]\n",
    "\n",
    "# Compute the confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "# Visualize the confusion matrix\n",
    "plt.figure(figsize=(14, 10))\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\n",
    "disp.plot(cmap=plt.cm.Blues, values_format='d', ax=plt.gca())\n",
    "\n",
    "# Customize the plot\n",
    "plt.title(\"Confusion Matrix\", fontsize=16, fontweight=\"bold\")\n",
    "plt.xlabel(\"Predicted Label\", fontsize=14)\n",
    "plt.ylabel(\"True Label\", fontsize=14)\n",
    "plt.xticks(rotation=90)  # Rotate x-axis labels vertically\n",
    "plt.grid(False)  # Disable grid for better visibility\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"confusion_matrix.png\")  # Save the plot\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 1794080,
     "sourceId": 2952603,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 3189529,
     "sourceId": 5549204,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6230269,
     "sourceId": 10101207,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6258471,
     "sourceId": 10140211,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6572749,
     "sourceId": 10616212,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6573356,
     "sourceId": 10617031,
     "sourceType": "datasetVersion"
    },
    {
     "modelId": 40,
     "modelInstanceId": 496,
     "sourceId": 629,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelId": 40,
     "modelInstanceId": 497,
     "sourceId": 630,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30381,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
