{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-05T05:27:25.119580Z",
     "iopub.status.busy": "2025-02-05T05:27:25.119271Z",
     "iopub.status.idle": "2025-02-05T05:27:25.407285Z",
     "shell.execute_reply": "2025-02-05T05:27:25.406405Z",
     "shell.execute_reply.started": "2025-02-05T05:27:25.119540Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-05T05:27:25.409397Z",
     "iopub.status.busy": "2025-02-05T05:27:25.409054Z",
     "iopub.status.idle": "2025-02-05T05:27:25.415576Z",
     "shell.execute_reply": "2025-02-05T05:27:25.414682Z",
     "shell.execute_reply.started": "2025-02-05T05:27:25.409359Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def image_to_patches(image, resize_to=(225, 225), patch_size=(15, 15)):\n",
    "    # Load the image\n",
    "    \n",
    "    if isinstance(image, Image.Image):\n",
    "        image = np.array(image)\n",
    "    \n",
    "    # Ensure the image is grayscale\n",
    "    if len(image.shape) == 3:  # Convert color image to grayscale\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    # Resize the image to the specified size\n",
    "    img = cv2.resize(image, resize_to)\n",
    "    \n",
    "    # Calculate the number of patches in each dimension\n",
    "    height, width = img.shape\n",
    "    patch_height, patch_width = patch_size\n",
    "    num_patches_y = height // patch_height\n",
    "    num_patches_x = width // patch_width\n",
    "    \n",
    "    # Initialize a matrix to store the average intensity of each patch\n",
    "    patch_matrix = np.zeros((num_patches_y, num_patches_x))\n",
    "    \n",
    "    # Compute the average intensity for each patch\n",
    "    for i in range(num_patches_y):\n",
    "        for j in range(num_patches_x):\n",
    "            patch = img[i * patch_height:(i + 1) * patch_height, j * patch_width:(j + 1) * patch_width]\n",
    "            patch_matrix[i, j] = np.mean(patch)\n",
    "    \n",
    "    return patch_matrix.astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Function of DFS to Find Best Path**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-05T05:27:25.417063Z",
     "iopub.status.busy": "2025-02-05T05:27:25.416716Z",
     "iopub.status.idle": "2025-02-05T05:27:25.431408Z",
     "shell.execute_reply": "2025-02-05T05:27:25.430410Z",
     "shell.execute_reply.started": "2025-02-05T05:27:25.417023Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def depth_map_search(matrix, start_row, start_col, threshold):\n",
    "    \n",
    "    rows, cols = len(matrix), len(matrix[0])\n",
    "    paths = []\n",
    "\n",
    "    def dfs(path, row, col):\n",
    "        # Add current position to the path\n",
    "        path.append((row, col))\n",
    "\n",
    "        # Skip path exploration for the top two rows\n",
    "        if row < 2:\n",
    "            return\n",
    "\n",
    "        # Current value\n",
    "        current_value = matrix[row][col]\n",
    "\n",
    "        # Check the neighbors\n",
    "        last_six_values = []\n",
    "        neighbors = [\n",
    "            (-1, -1), (-1, 0), (-1, 1),  # up-left, up, up-right\n",
    "            (-2, -1), (-2, 0), (-2, 1)   # up-up-left, up-up, up-up-right\n",
    "        ]\n",
    "\n",
    "        for dr, dc in neighbors:\n",
    "            new_row, new_col = row + dr, col + dc\n",
    "            if 0 <= new_row < rows and 0 <= new_col < cols:\n",
    "                last_six_values.append(matrix[new_row][new_col])\n",
    "\n",
    "        # Termination condition: consider the available neighbors\n",
    "        if last_six_values:\n",
    "            avg_neighbors = sum(last_six_values) / len(last_six_values)\n",
    "            if abs(avg_neighbors - current_value) <= threshold:\n",
    "                paths.append(path)\n",
    "                return\n",
    "\n",
    "        # Flag to track if further moves are possible\n",
    "        has_next = False\n",
    "\n",
    "        # Explore possible moves (up-left, up, up-right)\n",
    "        directions = [\n",
    "            (-1, 0), (-1, -1), (-1, 1)\n",
    "        ]\n",
    "\n",
    "        for dr, dc in directions:\n",
    "            new_row, new_col = row + dr, col + dc\n",
    "\n",
    "            # Check bounds and value condition\n",
    "            if 0 <= new_row < rows and 0 <= new_col < cols:\n",
    "                if matrix[new_row][new_col] <= current_value:\n",
    "                    has_next = True\n",
    "                    dfs(path[:], new_row, new_col)  # Pass a copy of the current path\n",
    "\n",
    "        # If no further moves are possible, save the path\n",
    "        if not has_next:\n",
    "            paths.append(path)\n",
    "\n",
    "    # Start DFS from the given starting point\n",
    "    dfs([], start_row, start_col)\n",
    "\n",
    "    # Select the most straight-forward and longest path\n",
    "    straight_forward_path = []\n",
    "    max_length = 0\n",
    "\n",
    "    for path in paths:\n",
    "        # Check if the path is the longest and prioritize straight-forward direction (upwards)\n",
    "        if len(path) > max_length or (len(path) == max_length and all(step[1] == start_col for step in path)):\n",
    "            straight_forward_path = path\n",
    "            max_length = len(path)\n",
    "\n",
    "    return straight_forward_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Function for Displaying Result Visually**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-05T05:27:25.432666Z",
     "iopub.status.busy": "2025-02-05T05:27:25.432338Z",
     "iopub.status.idle": "2025-02-05T05:27:25.446022Z",
     "shell.execute_reply": "2025-02-05T05:27:25.445195Z",
     "shell.execute_reply.started": "2025-02-05T05:27:25.432635Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def display_results_with_line(input_image_path, matrix, path):\n",
    "    matrix_np = np.array(matrix)\n",
    "    # input_image = cv2.imread(input_image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    input_image = np.array(input_image_path)\n",
    "\n",
    "    if not path:\n",
    "        print(\"No valid path found.\")\n",
    "        return 3 # Exit or handle as needed\n",
    "\n",
    "    # Extract (row, col) points from the path\n",
    "    rows, cols = zip(*path)\n",
    "\n",
    "    # Fit a straight line (polynomial of degree 1)\n",
    "    fit = np.polyfit(cols, rows, 1)\n",
    "    fit_fn = np.poly1d(fit)\n",
    "    slope = fit[0]\n",
    "    angle = np.degrees(np.arctan(slope))\n",
    "\n",
    "    print(\"Path Direction according to the clock's hour-hand is to: \", angle_to_number(angle))\n",
    "\n",
    "    # Generate fitted points for plotting\n",
    "    fitted_cols = np.linspace(min(cols), max(cols), 100)\n",
    "    fitted_rows = fit_fn(fitted_cols)\n",
    "\n",
    "\n",
    "\n",
    "    return angle_to_number(angle)"
   ]
  },
  {
   "attachments": {
    "f6c01265-c6b1-4e5a-9a99-f1c01a557f71.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Function for Angle to Hour-hand Direction**\n",
    "![The-main-directions-and-intermediate-representation-to-the-cardinal-and-time-zone-of-the (1).png](attachment:f6c01265-c6b1-4e5a-9a99-f1c01a557f71.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-05T05:27:25.447114Z",
     "iopub.status.busy": "2025-02-05T05:27:25.446853Z",
     "iopub.status.idle": "2025-02-05T05:27:25.458645Z",
     "shell.execute_reply": "2025-02-05T05:27:25.457837Z",
     "shell.execute_reply.started": "2025-02-05T05:27:25.447093Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def angle_to_number(angle):\n",
    "    if 0 <= angle < 15:\n",
    "        return 9\n",
    "    elif 15 <= angle < 30:\n",
    "        return '9:30'\n",
    "    elif 30 <= angle < 45:\n",
    "        return 10\n",
    "    elif 45 <= angle < 60:\n",
    "        return '10:30'\n",
    "    elif 60 <= angle < 75:\n",
    "        return 11\n",
    "    elif 75 <= angle < 90:\n",
    "        return '11:30'\n",
    "    elif -90 <= angle < -75:\n",
    "        return 12\n",
    "    elif -75 <= angle < -60:\n",
    "        return '12:30'\n",
    "    elif -60 <= angle < -45:\n",
    "        return 1\n",
    "    elif -45 <= angle < -30:\n",
    "        return '1:30'\n",
    "    elif -30 <= angle < -15:\n",
    "        return 2\n",
    "    elif -15 <= angle < 0:\n",
    "        return '2:30'    \n",
    "    \n",
    "    else:\n",
    "        return 3  # Default case if angle is out of range"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Function for Calculating Adaptive Threshold value**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-05T05:27:25.459904Z",
     "iopub.status.busy": "2025-02-05T05:27:25.459585Z",
     "iopub.status.idle": "2025-02-05T05:27:25.472415Z",
     "shell.execute_reply": "2025-02-05T05:27:25.471570Z",
     "shell.execute_reply.started": "2025-02-05T05:27:25.459874Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def find_lowest_six_avg(matrix):\n",
    "    matrix = np.array(matrix)\n",
    "    flat_values = np.sort(matrix.flatten())\n",
    "    lowest_six = flat_values[:6]\n",
    "    # print(lowest_six)\n",
    "    avg_lowest_six = np.mean(lowest_six)   \n",
    "    return avg_lowest_six"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Result**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-05T05:27:25.475606Z",
     "iopub.status.busy": "2025-02-05T05:27:25.475345Z",
     "iopub.status.idle": "2025-02-05T05:33:15.933272Z",
     "shell.execute_reply": "2025-02-05T05:33:15.932312Z",
     "shell.execute_reply.started": "2025-02-05T05:27:25.475560Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image, ImageOps\n",
    "import io\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from tabulate import tabulate  # Import tabulate for timing output\n",
    "\n",
    "MODEL_PATH = '/kaggle/input/midasv2/keras/default/1/Midas-V2.tflite'\n",
    "try:\n",
    "    interpreter = tf.lite.Interpreter(model_path=MODEL_PATH)\n",
    "    interpreter.allocate_tensors()\n",
    "    print(\"Model Loaded\")\n",
    "\n",
    "    # Check model details\n",
    "    input_details = interpreter.get_input_details()\n",
    "    output_details = interpreter.get_output_details()\n",
    "\n",
    "    print(\"Input Details:\", input_details)\n",
    "    print(\"Output Details:\", output_details)\n",
    "\n",
    "except ValueError as e:\n",
    "    print(\"Error loading the model:\", e)\n",
    "\n",
    "\n",
    "INPUT_HEIGHT = 256\n",
    "INPUT_WIDTH = 256\n",
    "\n",
    "INPUT_MEAN = 127.5\n",
    "INPUT_STD = 127.5\n",
    "\n",
    "MAX_IMAGE_SIZE = 65535  # Maximum allowed size for the image in bytes\n",
    "\n",
    "# Preprocess image to match model input size and normalize\n",
    "def preprocess_image(image: Image.Image) -> np.ndarray:\n",
    "    original_size = image.size  # Store the original image size\n",
    "\n",
    "    # Compress the image if its size is greater than 1 MB\n",
    "    img_byte_arr = io.BytesIO()\n",
    "    image.save(img_byte_arr, format='JPEG')\n",
    "    size_in_mb = len(img_byte_arr.getvalue()) / (1024 * 1024)\n",
    "\n",
    "    # If the image size exceeds 1 MB, we compress it\n",
    "    if size_in_mb > 1.0:\n",
    "        quality = int(min(85, 85 * (2.0 / size_in_mb)))  # Adjust quality based on size\n",
    "        compressed_io = io.BytesIO()\n",
    "        image.save(compressed_io, format='JPEG', quality=quality, optimize=True)\n",
    "        image = Image.open(compressed_io)\n",
    "\n",
    "    # Convert the image to RGB and resize to the input size\n",
    "    image = image.convert('RGB')\n",
    "    image = image.resize((INPUT_WIDTH, INPUT_HEIGHT))\n",
    "\n",
    "    # Convert the image to a NumPy array and normalize\n",
    "    image_np = np.array(image).astype(np.float32)\n",
    "    image_np = (image_np - INPUT_MEAN) / INPUT_STD  # Normalize\n",
    "    image_np = np.expand_dims(image_np, axis=0)  # Add batch dimension\n",
    "\n",
    "    return image_np, original_size\n",
    "\n",
    "# Postprocess depth map to match original size\n",
    "def postprocess_depth(depth: np.ndarray, original_size: tuple) -> Image.Image:\n",
    "    depth = np.squeeze(depth)\n",
    "\n",
    "    # Normalize the depth values to the range [0, 1]\n",
    "    depth_min = depth.min()\n",
    "    depth_max = depth.max()\n",
    "    depth_normalized = (depth - depth_min) / (depth_max - depth_min)\n",
    "\n",
    "    # Convert to a 0-255 range for visualization\n",
    "    depth_image = (depth_normalized * 255).astype(np.uint8)\n",
    "\n",
    "    depth_pil = Image.fromarray(depth_image)\n",
    "    depth_pil = depth_pil.resize(original_size, Image.Resampling.LANCZOS)\n",
    "\n",
    "    return depth_pil\n",
    "\n",
    "# Calculate patch values for a 5x5 grid\n",
    "def calculate_patch_values(depth_image: Image.Image) -> dict:\n",
    "    depth_array = np.array(depth_image)\n",
    "    h, w = depth_array.shape\n",
    "    patch_values = {}\n",
    "    patch_size_h = h // 5\n",
    "    patch_size_w = w // 5\n",
    "\n",
    "    for i in range(5):\n",
    "        for j in range(5):\n",
    "            patch = depth_array[i * patch_size_h:(i + 1) * patch_size_h,\n",
    "                                j * patch_size_w:(j + 1) * patch_size_w]\n",
    "            patch_values[5 * i + j + 1] = int(np.mean(patch))\n",
    "\n",
    "    return patch_values\n",
    "\n",
    "# Generate depth map from image\n",
    "def generate_depth_from_image(image_filename):\n",
    "    overall_start = time.time()\n",
    "\n",
    "    try:\n",
    "        timings = []\n",
    "\n",
    "        step_start = time.time()\n",
    "        image = Image.open(image_filename)\n",
    "        image = ImageOps.exif_transpose(image)\n",
    "        timings.append([\"Image Loading\", time.time() - step_start])\n",
    "\n",
    "        step_start = time.time()\n",
    "        input_data, original_size = preprocess_image(image)\n",
    "        timings.append([\"Preprocessing\", time.time() - step_start])\n",
    "\n",
    "        step_start = time.time()\n",
    "        interpreter.set_tensor(input_details[0]['index'], input_data)\n",
    "        interpreter.invoke()\n",
    "        timings.append([\"Model Inference\", time.time() - step_start])\n",
    "\n",
    "        step_start = time.time()\n",
    "        output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "        depth = output_data[0]\n",
    "        timings.append([\"Depth Map Extraction\", time.time() - step_start])\n",
    "\n",
    "        step_start = time.time()\n",
    "        depth_image = postprocess_depth(depth, original_size)\n",
    "        timings.append([\"Postprocessing\", time.time() - step_start])\n",
    "\n",
    "        return {\n",
    "            'depth_map': depth_image\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {image_filename}: {e}\")\n",
    "        return {'error': str(e)}\n",
    "\n",
    "import os\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "\n",
    "# Define paths\n",
    "dataset_path = \"\"\n",
    "csv_path = '/kaggle/input/path-for-outdoor-final/outdoor_gt_path.csv'\n",
    "\n",
    "# Load the CSV file and get the first column (image filenames)\n",
    "image_files = pd.read_csv(csv_path, header = None)  # Read CSV file\n",
    "gt_value = image_files.iloc[:, 1]\n",
    "image_files2 = image_files.iloc[:, 0]  # Select the first column (image filenames)\n",
    "\n",
    "# Create a list to store full image paths\n",
    "full_paths = []\n",
    "out_pred = []\n",
    "# Iterate through the first 10 filenames and construct the full path\n",
    "for filename in image_files2:\n",
    "    image_path = os.path.join(dataset_path, filename)  # Construct full path\n",
    "    full_paths.append(image_path)  # Store the full path in the list\n",
    "    # print(f\"Full path: {image_path}\")\n",
    "\n",
    "total_time = 0\n",
    "total_images = len(full_paths)\n",
    "overall_times = []\n",
    "tot_times = []\n",
    "\n",
    "for image_filename in full_paths:\n",
    "\n",
    "    start_time = time.time()\n",
    "    result = generate_depth_from_image(image_filename)\n",
    "    image_path = result['depth_map']  # Replace with your image path\n",
    "\n",
    "    # print(image_path)\n",
    "    # image = Image.open(image_path)  # Load the image\n",
    "    image_array = np.array(image_path) \n",
    "    # Convert image to patches and calculate average intensities\n",
    "    # print(image_array)\n",
    "    patch_matrix = image_to_patches(image_array, resize_to=(225, 225), patch_size=(15, 15))\n",
    "    \n",
    "    # print(patch_matrix)\n",
    "    th = find_lowest_six_avg(patch_matrix)\n",
    "    print(\"Threshold Value: \",th)\n",
    "    # Starting point (row, col) for path visualization\n",
    "    start_row, start_col = 14, 7\n",
    "    \n",
    "    # Perform the depth map search\n",
    "    longest_straight_forward_path = depth_map_search(patch_matrix, start_row, start_col, th)\n",
    "    \n",
    "    # Display the results with the fitted line and slope\n",
    "    result = display_results_with_line(image_array, patch_matrix, longest_straight_forward_path)\n",
    "\n",
    "    end_time = time.time()\n",
    "    tot_times.append(end_time-start_time)\n",
    "    out_pred.append(result)\n",
    "    \n",
    "    \n",
    "print(len(out_pred))\n",
    "print(tot_times)\n",
    "average_time = sum(tot_times) / len(tot_times)\n",
    "print(f\"Average response time: {average_time:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-05T05:33:15.939043Z",
     "iopub.status.busy": "2025-02-05T05:33:15.938799Z",
     "iopub.status.idle": "2025-02-05T05:33:15.953727Z",
     "shell.execute_reply": "2025-02-05T05:33:15.953048Z",
     "shell.execute_reply.started": "2025-02-05T05:33:15.939021Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10, '12:30', 10, 11, 11, 11, '12:30', '10:30', '1:30', 1, 10, 1, '9:30', '12:30', 1, 11, '9:30', '9:30', 11, 1, 3, '10:30', '9:30', '10:30', '12:30', '11:30', 11, '12:30', '11:30', '12:30', 10, 1, 10, '12:30', 11, 12, 11, 1, 3, '12:30', '10:30', 12, 1, 11, '11:30', 3, '9:30', 11, 11, 10, 1, 12, '10:30', 10, 1, '12:30', 1, 1, '12:30', 1, 12, '9:30', 11, 10, 11, 12, '12:30', '11:30', '11:30', '11:30', 12, '10:30', '10:30', '10:30', 10, '12:30', '2:30', 10, 3, 10, 1, '12:30', 10, 10, 11, 10, 12, 1, 12, '12:30', 10, 12, '11:30', '11:30', 1, '11:30', 1, '10:30', 11, 10, 11, 12, 11, '10:30', 12, 12, 11, 10, '10:30', 11, 10, 12, 12, 11, 1, '9:30', 10, 3, 11, '11:30', 12, 1, '10:30', '9:30', 12, 1, 10, 1, 11, '9:30', 3, 3, '11:30', '10:30', 10, 1, '12:30', 11, 12, 1, '10:30', '12:30', '12:30', 11, 11, 11, 10, 1, 12, 10, '10:30', 10, 11, 10, 1, '9:30', '12:30', '12:30', '12:30', '11:30', '12:30', 11, 11, '12:30', 11, '11:30', '12:30', '9:30', 12, '9:30', 11, 12, '12:30', '12:30', 11, '10:30', '12:30', '12:30', 10, '10:30', '12:30', 3, '9:30', '12:30', '11:30', 11, '10:30', '9:30', '12:30', 10, 12, 10, 1, 1, '10:30', '11:30', '12:30', '10:30', '12:30', '11:30', '12:30', 3, 11, 11, 3, 3, 12, 12, '9:30', 11, 12, '11:30', 10, '12:30', '12:30', 12, '10:30', '11:30', '12:30', 11, '11:30', 12, 10, '9:30', '9:30', '9:30', 3, '9:30', 11, 10, 11, '12:30', 10, '10:30', '11:30', '11:30', 11, 11, 10, '9:30', '12:30', '11:30', '12:30', 10, 10, '10:30', '1:30', 12, 10, '10:30', 10, 10, '9:30', '12:30', 3, '9:30', '10:30', 10, '9:30', 11, 10, '9:30', '10:30', 10, 10, 11, 1, 1, 12, '2:30', 12, '11:30', '11:30', 1, '12:30', 12, 11, 10, '11:30', '12:30', 12, 11, '11:30', 10, 11, 3, '12:30', 11, 12, '12:30', '10:30', 11, 10, 10, 1, 10, 10, '11:30', 1, '12:30']\n"
     ]
    }
   ],
   "source": [
    "print((out_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-05T05:33:15.954689Z",
     "iopub.status.busy": "2025-02-05T05:33:15.954426Z",
     "iopub.status.idle": "2025-02-05T05:33:15.972557Z",
     "shell.execute_reply": "2025-02-05T05:33:15.971761Z",
     "shell.execute_reply.started": "2025-02-05T05:33:15.954667Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 34.45 degree\n",
      "Accuracy: 34.66666666666667 %\n"
     ]
    }
   ],
   "source": [
    "def time_to_minutes(time_str):\n",
    "    # Handle times like 12, 11:30, 10:30, etc.\n",
    "    if \":\" in time_str:  # For times like 12:30, 10:30, etc.\n",
    "        hour, minute = map(int, time_str.split(\":\"))\n",
    "    else:  # For times like 12, 11, 10, etc.\n",
    "        hour, minute = int(time_str), 0\n",
    "    \n",
    "    # If hour is greater than or equal to 1, add 12 hours\n",
    "    if hour == 1 or hour == 2 or hour == 3:\n",
    "        hour += 12\n",
    "    \n",
    "    return hour * 60 + minute\n",
    "\n",
    "def calculate_time_difference(gt_val, out_val):\n",
    "    # Convert both gt_val and out_val to minutes\n",
    "    gt_time_in_minutes = time_to_minutes(gt_val)\n",
    "    out_time_in_minutes = time_to_minutes(out_val)\n",
    "\n",
    "    # print(gt_time_in_minutes, out_time_in_minutes, similar_cnt)\n",
    "    # Calculate the absolute difference\n",
    "    return abs(gt_time_in_minutes - out_time_in_minutes)\n",
    "\n",
    "# print(len(gt_value), len(out_pred))\n",
    "out_pred = ['3' if val is None else val for val in out_pred]\n",
    "# print(out_pred)\n",
    "# Example for the 5 iterations\n",
    "size = 300\n",
    "tot_dig = 0\n",
    "similar_cnt = 0\n",
    "for i in range(size):\n",
    "    gt_val = str(gt_value[i]).replace(\" \", \"\")\n",
    "    out_val = str(out_pred[i]).replace(\" \", \"\")\n",
    "    time_diff = calculate_time_difference(gt_val, out_val)\n",
    "    # if time_diff <= 30:\n",
    "    #     time_diff = 0\n",
    "    if time_diff == 0:\n",
    "        similar_cnt += 1\n",
    "    tot_dig += time_diff * 0.5\n",
    "\n",
    "print(\"MAE:\", tot_dig / size, \"degree\")\n",
    "print(\"Accuracy:\", (similar_cnt / size) * 100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 1198025,
     "sourceId": 2002504,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 1886240,
     "sourceId": 3085320,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6435105,
     "sourceId": 10387292,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6590365,
     "sourceId": 10643693,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6590668,
     "sourceId": 10644127,
     "sourceType": "datasetVersion"
    },
    {
     "modelId": 229682,
     "modelInstanceId": 207980,
     "sourceId": 243472,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30822,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
